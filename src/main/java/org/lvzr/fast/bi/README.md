
入门书
Pang-Ning Tan, Michael Steinbach  ， Vipin Kumar， 数据挖掘导论
分类、关联、聚类
分类：决策树、随机森林、基于规则的分类、神经网络、支持向量机、朴素贝叶斯分类、最近邻
关联：
聚类：K均值、凝聚的层次聚类、DBSCAN

EM迭代算法
决策树：Hunt算法->ID3、C4.5、CART、信息熵增溢
提升方法Adaboost


###基本算法
梯度下降法
牛顿法
拉格朗日对偶性
损失函数
最大似然估计


-------------------------------------------------------------------------------------------------
#概率论

###朴素贝叶斯


###贝叶斯网络


###逻辑斯帝与最大熵模型
http://www.cnblogs.com/KevinYang/archive/2009/02/01/1381798.html
决定股票涨落的因素可能有几十甚至上百种，而最大熵方法恰恰能找到一个同时
满足成千上万种不同条件的模型。达拉皮 垂兄弟等科学家在那里，用于最大熵模型和其他一些先进的数学工具对股票预测，获得了巨大的成功
最大熵模型是百花齐放的指数模型的一种，它表示的这类分布有着有趣的数学和哲学性质
值得一提的是，信息处理的很多数学手段，包括隐含马尔可夫模型、子波变换、贝叶斯网络等等，在华尔街多有直接的应用。由此可见，数学模型的作用。

###隐马尔柯夫模型
http://www.cnblogs.com/skyme/p/4651331.html


###条件随机场
基于隐马尔柯夫模型+最大熵模型





假设检验
方差分析
--------------------
回归、岭回归




熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。
在信息论里则叫信息量,即熵是对不确定性的度量。从控制论的角度来看，应叫不确定性。
信息论的创始人香农在其著作《通信的数学理论》中提出了建立在概率统计模型上的信息度量。
他把信息定义为“用来消除不确定性的东西”。在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。
当我们不知道某事物具体状态，却知道它有几种可能性时，显然，可能性种类愈多，不确定性愈大。不确定性愈大的事物，我们最后确定了、
知道了，这就是说我们从中得到了愈多的信息，也就是信息量大。所以，熵、不确定性、信息量，这三者是同一个数值。
http://blog.csdn.net/hguisu/article/details/27305435
熵=信息量=log2(N)=log(N)/log2，就是通过二叉树逐层辨别确定是否是某个符号的的层次数



统计分析/机器学习吐血整理最强指南http://mp.weixin.qq.com/s?
http://www.cnblogs.com/hark0623/p/5533798.html

北大数据分析老鸟写给学弟们一封信
http://suanfazu.com/t/bei-da-shu-ju-fen-xi-lao-niao-xie-gei-xue-di-men-feng-xin/35

SPSS_入门讲义
https://wenku.baidu.com/view/16ad9cdbaeaad1f346933fb1.html

对应分析方法与对应图解读方法――七种分析角度
http://shenhaolaoshi.blog.sohu.com/133694659.html

BI分析:基本统计分析、分组统计、相关分析、方差分析、进度分析、ABC分析、TOPN分析、雷达图分析、预警分析
BI数据挖掘：决策树分析、时间序列预测分析、多元线性回归分析、关联分析、聚类分析

PCA（主成份分析）
实验发现，PCA对于线性模型（不使用Lasso）非常有效，但是对于随机森林模型没有提高。


分析方法：聚类分析、因子分析、相关分析、对应分析、回归分析、方差分析(ANOVA/F检验/不同组别指标的差异显著性水平)、T检验
数据分析工具：SPSS、SAS、SYSSTAT、tableau
发展方向：R语言和Pythone

数据分析分为三层：统计分析、基本分析、数据挖掘
企业有80%的工作只需要掌握统计分析、剩下20%需要更深入的分析及挖掘，更深入的需要市场细分、客户特征提取等

企业外部环境需要PEST模型，从政策、经济、社会和技术四个方面地分析
如果从竞争分析，需要懂得SWOT、波特五力
最简单的实用的从5W2H模型，what、where、why、when、who、how、how much广泛用于营销活动、用户行为分析等专题分析


因子分析
因子分析是指研究从变量群中提取共性因子的统计技术。最早由英国心理学家C.E.斯皮尔曼提出。他发现学生的各科成绩之间存在
着一定的相关性，一科成绩好的学生，往往其他各科成绩也比较好，从而推想是否存在某些潜在的共性因子，或称某些一般智力条
件影响着学生的学习成绩。因子分析可在许多变量中找出隐藏的具有代表性的因子。将相同本质的变量归入一个因子，可减少变量的
数目，还可检验变量间关系的假设。


如果根据理论或逻辑已经预设了变量间的因果关系，那么就无需使用实验方法。我对非实验数据分析工具的选择原则如下。

因变量为连续变量，自变量至少有一个连续变量，进行多元线性回归；
因变量为连续变量，自变量全部为分类变量，进行方差分析；
因变量为分类变量，自变量至少有一个连续变量，使用Logit模型或Probit模型；
因变量为分类变量，自变量全部为分类变量，进行交叉表分析和卡方检验；

因变量在某个闭区间内分布，并且有较多样本落在闭区间的边界上，使用Tobit模型；
因变量不唯一，如多产出问题，进行数据包络分析（DEA）；
因变量为整数、数值小、取零个数较多，使用计数（Count）模型；
数据具有层次结构（嵌套结构），使用多层线性模型（HLM）。


随着统计和计量经济学的发展，各种前沿分析工具层出不穷，但我认为最靠谱的分析工具不外乎以下四种：
DID（针对随机实验）
多元线性回归
固定效应变截距模型（FE，针对面板数据）
Logit模型或Probit模型（针对分类因变量数据）。


其他方法或适用条件苛刻，或分析过程折腾，或方法本身不可靠（尤其是聚类分析、判别分析，超级不靠谱），因此能用以上四种方法分析问题时，
不必为“炫方法”而瞎折腾。

###方差分析
方差分析(Analysis of Variance，简称ANOVA)，又称“变异数分析”或“F检验”，是R.A.Fisher发明的，用于两个及两个以上样本均数差别的显着性检验。 
由于各种因素的影响，研究所得的数据呈现波动状。造成波动的原因可分成两类，一是不可控的随机因素，另一是研究中施加的对结果形成影响的可控因素。 
方差分析是从观测变量的方差入手，研究诸多控制变量中哪些变量是对观测变量有显着影响的变量。

##t检验
是假设检验的一种常用方法，当方差未知时，可以用来检验一个正态总体或两个正态总体的均值
检验假设问题，也可以用来检验成对数据的均值假设问题。具体内容可以参考《概率论与数理统计》。可
以用来判断两组数倨差异是否有显著意义，也就是结果有没有统计学意义。

##方差分析
它是处理实验研究资料时重要的分析方法之一，代表数据是否具有统计意义, 
一般一组数据代表某个条件或因素,方差分析可以判断你选取的这个因素是否有意义,是不是影响因素
如果你做统计为了找到事物相关性,而方差结果显示数据无统计学差异,很可能代表实验失败或设计有问题














